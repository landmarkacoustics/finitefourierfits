---
title: "lab-notebook"
output: rmarkdown::html_vignette
description: >
  A lab notebook for finitefourierfits. This is basically a dev diary.
vignette: >
  %\VignetteIndexEntry{lab-notebook}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(finitefourierfits)
```
# 2020 July 13-15

I developed the basic algorithm ideas over these days. The goal is to take a
bivariate relation that seems to be functional and fit a partial Fourier basis
to it. Fewer terms will mean less computational complexity and more smoothness.

The steps that I came up with are

1. pad the response variable with zeros so that its length is more than doubled
and a power of two.

1. find a mapping, `u(x)`, from the causal variable to angular frequency.

1. compute the DFT of the padded variable with `fft`

   1. use `Mod` to compute `a`, the amplitudes of each term in the DFT.
   
   1. use `Arg` to compute `p`, the phases of each term in the DFT.

1. choose a limited number of terms to include

   1. I started by trying to quantify the proportion of information captured by
   each term
   
   1. I ended up just using a fixed number of terms
   
1. build a formula to use with `nls`

   1. the l.h.s. is just the response variable 

   1. the r.h.s is built from the DFT's terms
   
      1. if the CF term is included, just add a term called `b`.
      
      1. if term `i` is included, add `a{i} * cos({i-1} * u(x) + {p[i]})`
      
         1. if `i=3` & `p[3] =-1.1` then the term is `a3 * cos(2 * u(x) - 1.1)`
         
   1. it turned out that the phases didn't change much when I let them vary,
   so I decided to set them as constants. This may cause problems with
   numerical precision because they are actually pasted into the formulae.
   
1. run the `nls` fit to find the values of `b` (if necessary) and the `a_i`s

1. the resulting function is the approximation.

Here's what it looked like after I plugged away for a while. Bonus: I won't get
annoying messages about commented code after I put it here!

```{r}
x <- seq(-2, 2, length.out=401)
N <- length(x)
fft.size <- 4 * nextn(N, 2)
half <- floor(fft.size / 2)
omegas <- finitefourierfits::omegas(fft.size)
b <- x[1]
Hz <- (N-1)/(x[N]-b)
d.omega <- (fft.size-1)/omegas[fft.size]
m <- Hz / d.omega
u <- function(x) {m*(x-b)}
plot(x, u(x), las=1, pch=16, col='blue',
     xlab=expression(x), ylab=expression(u(x)))
y <- (x-rnorm(1))*(x-rnorm(1))*(x-rnorm(1))
mu <- mean(y)
S <- fft(c(y - mu, rep(0, fft.size-N)))
a <- finitefourierfits::.amplitudes(S)
p <- finitefourierfits::.phases(S)
mag.order <- order(a, decreasing=TRUE)[1:10]
all.terms <- build.term.list(mag.order, p)
all.starts <- a[mag.order]
names(all.starts) <- names(all.terms)
all.starts
step.fits <- list()
for(i in 1:10) {
    ix <- 1:i
    tmp <- tryCatch(nls(formula(paste("y-mu ~",
                                      paste(all.terms[ix], collapse=" + "))),
                        data.frame(w=u(x), y=y),
                        start=all.starts[ix]),
                    error=function(e) NULL)
    if(!is.null(tmp)){
        step.fits <- append(step.fits, list(tmp))
    }
}
if (length(step.fits)) {
    scores <- sapply(step.fits, BIC)
    tops <- match(min(scores), scores)
    plot(x, y,
	     las=1, col="blue",
		 xlab=expression(x), ylab=expression(f(x)))
    lines(x, predict(step.fits[[tops]])+mu, col="orange", lwd=2)
	summary(step.fits[[tops]])
}
```

# 2020 July 16

This was the first day that I started working on this project as a package.
I am using Hadley Wickham's [e-book](http://r-pkgs.had.co.nz) about making R
packages as a guide. The first hour was spent installing the tools. Wickham's
package, `devtools`, depends on the library `pandoc` and the development
libraries for `curl` and `openssl`. The error messages from the failed install
ended up leading me to them. In general, the e-book is not up-to-date with the
CRAN package including, ironically, creating vignettes. I actually didn't write
any vignette on this day at all. I did create roxygen documentation for some
functions, made progress with the linter `lintr`, and wrote some unit tests as
well.


# 2020 July 17

## Getting vignettes to work

Today is when I actually started writing this vignette. One guide that I am
following is Robert M. Flight's
[blog post](http://rmflight.github.io/posts/2014/07/vignetteAnalysis.html)
about using vignettes to document the process of creating a package.

**I DIDN'T USE `devtools::check` YESTERDAY. IT'S AWESOME.**

Don't use `@examples` in internal functions!

*AHA!* This [e-book](http://r-pkgs.had.co.nz) is out-of-date because they broke
`devtools` into sub-packages for DRY reasons. The `usethis` package (which
is now a dependency of `devtools` is now the namespace for some of the
functions. [This site](https://www.tidyverse.org/blog/2018/10/devtools-2-0-0/)
has details.

There are a lot of problems in getting Rmarkdown to work. The markdown renderer
libraries `pandoc` **AND** `pandoc-citeproc` need to be installed. Also, some
stage of the renderer tries to work with EMACS temporary files and crashes, so
you can't have unsaved changes to any of the vignette markdown files. Maybe
this is a feature, not a bug??

## Linting

I can't seem to get the `devtools::lint` to listen to my customizations. This
does work, though:
```{r eval=FALSE}
my.linters <- lintr::with_defaults(
  object_name_linter=lintr::object_name_linter(styles="dotted.case"),
  infix_spaces_linter=NULL,
  commented_code_linter=NULL
)
lintr::lint_package(linters=my.linters)
```
My code style will depart from Wickham's in three ways:

1. Dotted case names are *de rigeur* b/c ESS shortcuts undercore to assignment

1. I will use Python code style for spaces around infix operators.

1. Sometimes I have commented code as I work. I don't need to be reminded.

## Actually developing the package

Now that I have a workflow up and running, I need to keep working on the code.
Today's goal is to implement a more object-oriented interface to creating the
fits. I need to encapsulate the steps because my goal is an interface like:
```{r eval=FALSE}
my.fit <- fffit(my.data$x, my.data$y, model.selector=BIC)
my.fit$n.terms
coef(my.fit)
```
My initial attempts at a monolithic function were not wildly successful. In
particular, it is hard to debug. This is one of the problems with R, though.
Pass-by-value means that there are nasty performance consequences to breaking
an algorithm into component steps. I'm going to make it an object at some
point, anyway, but it feels weird to break up what is essentially an ctor
into steps.

One quick gotcha is that tryCatch hides errors. I shouldn't activate it until
I am ***SURE*** that everything eles works.

I think I got it working:

```{r}
x <- seq(-2, 2, length.out=401)
y <- 10*(x/2)^2 + rnorm(length(x))
tmp <- finitefourierfits::fffit(x, y)
summary(tmp)
plot(x, y, las=1, col='blue', pch=16, xlab=expression(x), ylab=expression(f(x)))
lines(x, predict(tmp), col='orange', lwd=2)
```

# 2020 July 20

The next step is to turn this stuff into an S3 object interface. Initially,
I thought that I wanted to just save the best fit, but now I think I want to
save all of the fits that work and the index of the best fit.

The functions that I want to define for this

predict
~ Predicted values for some new data from the best (or a specified) model, or
the fitted values from the best (or specified) model.

~~plot~~
~ Draw a scatter plot with the data and a fit through it. This is actually too
hard to do right now.

coef
~ The coefficients of the best model, or optionally an indexed fit

formula
~ The formula of the best model, or optionally an indexed fit

summary
~ Summarize the best fit, or optionally an indexed fit

anova
~ compare all of the fits in order of degrees of freedom and likelihood

### side note about configuring `lintr`
You can avoid re-creating `my.linters` every time you lint with a  `.linter`
configuration file in the project directory. It irritates `devtools::check`,
though.
